{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from linear_sample_3c import *\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from read_images import *#不带模糊\n",
    "#from read_images_flur import *#带模糊，输出左图，右图和模糊\n",
    "import os\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = namedtuple(\"parameters\",\n",
    "                          'data_size,'\n",
    "                           'mini_batch_size,'\n",
    "                           'learning_rate,'\n",
    "                           'total_epoch_num,'\n",
    "                           'outputdir,'\n",
    "                           'height,'\n",
    "                           'width,'\n",
    "                           'channel,'\n",
    "                          'cutTop,'\n",
    "                          'cutBottom,'\n",
    "                          'cutLeft,'\n",
    "                          'cutRight,'\n",
    "                          'cPointRow,'\n",
    "                          'cPointCol')\n",
    "\n",
    "def compute_rec_loss170(est_im, real_im, compensateI, sz_params, A, cu_A, point_meshgrid):\n",
    "    \"\"\"\n",
    "    sz_params = size_params(batch=50,\n",
    "                            height=288,\n",
    "                            width=360,\n",
    "                            channel=3,\n",
    "                            cutTop=20,\n",
    "                            cutBottom=0,\n",
    "                            cutLeft=0,\n",
    "                            cutRight=50)\n",
    "    \"\"\"\n",
    "    d_height, d_width = get_tps_size(sz_params)\n",
    "    # d_height = sz_params.height - sz_params.cutTop\n",
    "    # d_width = sz_params.width - sz_params.cutRight\n",
    "    est_clip = tf.slice(est_im, [0,  sz_params.cutTop, sz_params.cutLeft, 0], [-1, d_height, d_width, -1],\n",
    "                        name='est_r_clip')\n",
    "    real_clip = tf.slice(real_im, [0,  sz_params.cutTop, sz_params.cutLeft, 0], [-1, d_height, d_width, -1],\n",
    "                         name='r_clip')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    real_clip_gray = tf.image.rgb_to_grayscale(real_clip)\n",
    "    est_im_gray = tf.image.rgb_to_grayscale(est_clip)\n",
    "    print(real_clip_gray)\n",
    "\n",
    "    #平铺   镜面反射：左图右图均有，左图映射过来，视差图为右图，所以只能消去右图的，消去左图会导致全局向镜面反射点收敛\n",
    "    ##左图的镜面反射点，应当对x小的右图点\n",
    "    shape = tf.shape(real_clip_gray)\n",
    "    jm = tf.fill(shape,160.0)#####如何筛选出正确的镜面反射区域,使用全部rgb都大于235来判断，在白机械臂干扰，还是有问题\n",
    "    \n",
    "    #shape2 = tf.shape(left_im_sum)\n",
    "    #jm3 = tf.fill(shape2,680.0)\n",
    "\n",
    "    compa2=tf.less(real_clip_gray,jm)###右图没有镜面反射的区域 所有小于650的为1 50,256,256,3\n",
    "    compa3=tf.less(est_im_gray,jm)###右图没有镜面反射的区域 所有小于650的为1 50,256,256,3\n",
    "    \n",
    "    \n",
    "    \n",
    "    compa = tf.to_float(compa2&compa3)\n",
    "    #compa = tf.to_float(compa3)\n",
    "    \n",
    "    #compa = tf.expand_dims(compa, -1)\n",
    "    kernel = tf.zeros([3,3,1],dtype = tf.float32)\n",
    "    compa_erosion = tf.nn.erosion2d(compa, kernel, strides = [1, 1, 1, 1], rates = [1, 1, 1, 1], padding=\"SAME\")###compa是整个图片计算损失函数的区域\n",
    "    compa_rgb = tf.tile(compa_erosion,[1,1,1,3])\n",
    "    \n",
    "    \n",
    "    ###batch误差和初除总点数\n",
    "    #loss_rec_sum = tf.reduce_sum(tf.multiply(tf.square(est_clip - real_clip - compensateI),compa_rgb))\n",
    "    #compa_sum = 3*tf.reduce_sum(compa_erosion)\n",
    "    #loss_rec = tf.math.divide(loss_rec_sum,compa_sum) \n",
    "    \n",
    "    ###batch每张图片的像素误差的平均\n",
    "    #loss_rec_sum = tf.reduce_sum(tf.multiply(tf.square(est_clip - real_clip - compensateI),compa_rgb), axis = [1,2,3])\n",
    "    #print(loss_rec_sum)\n",
    "    #compa_sum = tf.reduce_sum(compa_rgb,axis = [1,2,3])\n",
    "    #print(compa_sum)\n",
    "    #loss_rec = tf.reduce_mean(tf.divide(loss_rec_sum,compa_sum))\n",
    "    \n",
    "    ####batc每张图片误差和平均\n",
    "    loss_rec_sum = tf.reduce_sum(tf.multiply(tf.square(est_clip - real_clip - compensateI),compa_rgb), axis = [1,2,3])\n",
    "    #print(loss_rec_sum)\n",
    "    loss_rec = tf.reduce_mean(loss_rec_sum)\n",
    "    \n",
    "    compa_sum = tf.reduce_sum(compa_rgb)###这个batch的mask总点数\n",
    "    \n",
    "    #####计算拉普拉斯平滑项\n",
    "    A_loss = cu_A - A\n",
    "    A_loss = tf.reshape(A_loss, [1,200,200,16])\n",
    "    A_loss_ = tf.transpose(A_loss,[3,1,2,0])\n",
    "    filter_ = np.array([[1,1,1],[1,-8,1],[1,1,1]]).reshape(3,3,1,1)###3*3,输入3通道，输出3通道\n",
    "    filter_1 = tf.constant(filter_,dtype = 'float32')\n",
    "    Laplace_img = tf.nn.conv2d(input = A_loss_,filter = filter_1,strides=[1,1,1,1],padding='SAME')\n",
    "    print(Laplace_img)####1, 248, 270, 20\n",
    "    \n",
    "    loss_A_smooth = 40000*tf.reduce_sum(tf.square(Laplace_img))#+0.01*tf.reduce_sum(tf.abs(Laplace_img))##0.8\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #####计算每个点的影响是否越界，每张控制图上的16个控制点位置，当前A和初始A之间的差值的平方256\n",
    "    \n",
    "    #使用gather函数直接提取对应位置的值进行计算  point_meshgrid\n",
    "    \n",
    "    #point_all = tf.gather_nd(A_loss, point_meshgrid)\n",
    "    #point_all = tf.gather_nd(tf.reshape(A, [1,240,240,16]), point_meshgrid)\n",
    "    #print(point_all)\n",
    "    \n",
    "    #loss_point = 0.1*tf.reduce_sum(tf.square(point_all)) \n",
    "    \n",
    "    return loss_rec, loss_A_smooth, compa_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_feature(params, feature_in, left_ims, right_ims, tps_base, tps_matrix, linear_interpolator,update_total):\n",
    "    print_str = 'train_tps_Step：{:4} | Reonstruction loss is {:4}  | Asmooth loss is {:4} | Total loss is {:4}' \\\n",
    "                ' |  feature_var_mean is{:4}'\n",
    "    # with tf.Graph().as_default(), tf.device('/gpu: 0'):\n",
    "    max_step = np.int32(params.total_epoch_num)\n",
    "    learning_rate_init = np.float32(params.learning_rate)\n",
    "\n",
    "    optimize_op1 = tf.train.AdamOptimizer(learning_rate_init)##z\n",
    "    \n",
    "    tps_mat = tps_matrix\n",
    "    feature_next = feature_in\n",
    "    xymeshgrid = np.load('xymeshgrid.npy')\n",
    "    \n",
    "    \n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        tps_base = tf.constant(tps_base, dtype=tf.float32)\n",
    "        left = tf.constant(left_ims[0:params.data_size], dtype=tf.float32)\n",
    "        right = tf.constant(right_ims[0:params.data_size], dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        feature_f = tf.constant(feature_in, dtype=tf.float32)\n",
    "        #feature_f = tf.placeholder(tf.float32, shape=(50, 16, 1))\n",
    "        tps_weight_TRUE = tf.constant(tps_matrix, dtype=tf.float32)\n",
    "        tps_weight_f = tf.constant(tps_matrix, dtype=tf.float32)\n",
    "        #tps_weight_f = tf.placeholder(tf.float32, shape=(57600,16))\n",
    "        compensateI = tf.Variable(4.3, dtype=tf.float32, name='contr_val')###亮度补偿\n",
    "        \n",
    "        \n",
    "        feature_in_base = tf.constant(feature_in, dtype=tf.float32)\n",
    "        disp_base = tf.zeros([params.data_size, 288, 360, 1], dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        feature_input = tf.Variable(feature_f, dtype=tf.float32, name='contr_val')\n",
    "        tps_weight = tf.Variable(tps_weight_f, dtype=tf.float32)\n",
    "        update1 = tf.assign(feature_input,feature_f)\n",
    "        update2 = tf.assign(tps_weight,tps_weight_f)\n",
    "        \n",
    "        \n",
    "\n",
    "        disp2 = decoder_forward2(feature_input, feature_in_base, tps_weight, disp_base, linear_interpolator.sz_params)\n",
    "        \n",
    "        right_est2 = linear_interpolator.interpolate(left, disp2)###交替训练生成右图\n",
    "        #loss_rec = compute_rec_loss(right_est, right, linear_interpolator.sz_params)\n",
    "        \n",
    "        loss_rec2, loss_A_smooth2, compa_sum2 = compute_rec_loss170(right_est2, right, compensateI, linear_interpolator.sz_params, tps_weight_TRUE, tps_weight, xymeshgrid)\n",
    "\n",
    "        #loss_rec, loss_wt_norm, loss_rec_bijiao, loss_rec_batch = compute_rec_loss4(right_est, right, left, disp, linear_interpolator.sz_params)##使用膨胀做部分平滑\n",
    "        #loss_rec = compute_rec_loss3(right_est, right, left, linear_interpolator.sz_params)\n",
    "        \n",
    "        \n",
    "        loss2 = tf.add(loss_rec2, loss_A_smooth2, name='Total_loss2')\n",
    "        \n",
    "        ###优化器设置\n",
    "        train_op1 = optimize_op1.minimize(loss_rec2,var_list = feature_input)#可以指定哪些参数进行迭代\n",
    "    \n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    print(1)\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        \n",
    "        print(1.1)\n",
    "        start_time = time.time()\n",
    "        loss_rec_temp = 0.\n",
    "        print(1.2)\n",
    "        \n",
    "        feature_before = feature_in\n",
    "        feature_val = 0.\n",
    "        tps_before = tps_matrix\n",
    "        tps_val = 0.\n",
    "        disp_val = np.zeros([params.data_size, params.height, params.width, 1])\n",
    "        est_right_val = np.zeros([params.data_size, params.height, params.width, params.channel])\n",
    "        step = 0\n",
    "        print(2)\n",
    "        \n",
    "        \n",
    "        feature_base_ = np.load('groundtruth_z/z_batch_invivo_mean.npy')#16*1###分别是平均的d和z\n",
    "        feature_base_ =  np.tile(feature_base_,(params.data_size, 1, 1))\n",
    "        \n",
    "        disp_base_val = np.load('groundtruth_z/disp_batch_invivo_mean.npy')\n",
    "        disp_base_val =  np.tile(disp_base_val,(params.data_size, 1, 1, 1))\n",
    "        \n",
    "               \n",
    "        start_time = time.time()\n",
    "        loss_result = []\n",
    "        ######训练z\n",
    "        print(\"训练z\")\n",
    "        for step in range(0, max_step):\n",
    "            _, feature_val, tps_val, loss_rec_val,loss_A_smooth_val,compa_sum2_val,loss_val, disp_val, est_right_val = sess.run(\n",
    "                [train_op1, feature_input, tps_weight, loss_rec2,loss_A_smooth2,compa_sum2,loss2, disp2, right_est2],\n",
    "                feed_dict={feature_f:feature_next,tps_weight_f:tps_mat,feature_in_base:feature_base_, disp_base:disp_base_val})\n",
    "                \n",
    "            feature_next = feature_val\n",
    "            if  0 == step % 10 or step + 1 == max_step:\n",
    "                print('亮度补偿', sess.run(compensateI))\n",
    "                loss_result.append([copy.deepcopy(loss_rec_val)*params.data_size,copy.deepcopy(compa_sum2_val)])\n",
    "                tps_var_mean = np.mean(tps_val - tps_before)\n",
    "                feature_var_mean = np.mean(feature_val - feature_before)\n",
    "                print(loss_rec_val*20/compa_sum2_val)\n",
    "                print(print_str.format(step, loss_rec_val,loss_A_smooth_val, loss_val, feature_var_mean))#当前组的loss信息\n",
    "                tps_before = tps_val\n",
    "                feature_before = feature_val\n",
    "\n",
    "                loss_rec_var = np.abs(loss_rec_val - loss_rec_temp)\n",
    "                loss_rec_temp = loss_rec_val\n",
    "                if step >=150:#######考虑使用loss，比较一下和重建误差的区别\n",
    "                    feature_val, tps_val, loss_rec_val,loss_A_smooth_val,loss_val, disp_val, est_right_val = sess.run(\n",
    "                [feature_input, tps_weight, loss_rec2,loss_A_smooth2,loss2, disp2, right_est2],\n",
    "                feed_dict={feature_f:feature_next,tps_weight_f:tps_mat,feature_in_base:feature_base_, disp_base:disp_base_val})\n",
    "                    feature_next = feature_val\n",
    "                    loss_rec_temp = loss_rec_val\n",
    "                    print(loss_rec_val)\n",
    "                    break\n",
    "        feature = feature_val####z\n",
    "        if tps_val.any() == tps_mat.any():\n",
    "            print(\"z结束\")\n",
    "        tps_mat = tps_val\n",
    "        print('time spent {:8} '.format(time.time() - start_time))\n",
    "        distance = np.mean(np.square(feature - feature_in))\n",
    "        print('初始与终值的距离为:'+str(distance))\n",
    "        \n",
    "            \n",
    "            \n",
    "             \n",
    "        \n",
    "        \n",
    "        return feature, tps_mat, disp_val, est_right_val, distance, loss_rec_val, loss_result\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def train_z(params, feature_in, tps_base0, left_ims, right_ims, alpha, result_path,iii, update_total):\n",
    "    with tf.Graph().as_default(), tf.device('/gpu: 0'):\n",
    "        linear_interpolator = LinearInterpolator(params)  # initialize linear interpolator\n",
    "        tps_matrix = tps_base0\n",
    "        loss_seq = np.empty(shape=[0, 3], dtype=np.float32)\n",
    "        print('--------------------FEATURE---------------------')\n",
    "        feature_in, tps_matrix,  disp, est_right, distance, loss_rec_val, res_loss= train_feature(params, feature_in, left_ims, right_ims, tps_base0,\n",
    "                                                                           tps_matrix, linear_interpolator,update_total)\n",
    "        \n",
    "        np.save(os.path.join(result_path, 'disp_batch_invivo20_'+str(iii)+'.npy'), disp)\n",
    "        #np.save(os.path.join(result_path, 'est_right_invivo20'+str(iii)+'.npy'), est_right)\n",
    "        #np.save(os.path.join(result_path, 'tps_trained_.npy'), tps_matrix)\n",
    "        #np.save(os.path.join(result_path, 'feature_trained_'+str(iii)+'.npy'), feature_in)\n",
    "        #np.save(os.path.join(result_path, 'feature_trained_invivo'+str(iii)+'.npy'), feature_in)\n",
    "        #np.save(os.path.join(result_path, 'feature_trained_laststep.npy'), feature_in)\n",
    "        #np.save(os.path.join(result_path, 'loss_invivo20'+str(iii)+'.npy'), loss_rec_batch_val)\n",
    "        return res_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"meshgrid/mul:0\", shape=(288, 360), dtype=float32, device=/device:GPU:0) Tensor(\"meshgrid/mul_1:0\", shape=(288, 360), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Reshape:0\", shape=(1, 103680), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_1:0\", shape=(1, 103680), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Tile:0\", shape=(100, 103680), dtype=float32, device=/device:GPU:0) Tensor(\"Tile_1:0\", shape=(100, 103680), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"Reshape_2:0\", shape=(10368000,), dtype=float32, device=/device:GPU:0) Tensor(\"Reshape_3:0\", shape=(10368000,), dtype=float32, device=/device:GPU:0)\n",
      "--------------------FEATURE---------------------\n",
      "Tensor(\"sub_2:0\", shape=(100, 16, 1), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"map/TensorArrayStack/TensorArrayGatherV3:0\", shape=(100, 40000, 1), dtype=float32)\n",
      "Tensor(\"Add:0\", shape=(100, 288, 360, 1), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"rgb_to_grayscale:0\", shape=(100, 200, 200, 1), dtype=float32, device=/device:GPU:0)\n",
      "WARNING:tensorflow:From <ipython-input-2-7e5c86c38aa1>:56: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "Tensor(\"Conv2D:0\", shape=(16, 200, 200, 1), dtype=float32, device=/device:GPU:0)\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "1\n",
      "1.1\n",
      "1.2\n",
      "2\n",
      "训练z\n",
      "亮度补偿 4.3\n",
      "34.9152675050279\n",
      "train_tps_Step：   0 | Reonstruction loss is 19982252.0  | Asmooth loss is  0.0 | Total loss is 19982252.0 |  feature_var_mean is 0.0\n",
      "亮度补偿 4.3\n",
      "19.254340480405656\n",
      "train_tps_Step：  10 | Reonstruction loss is 11011798.0  | Asmooth loss is  0.0 | Total loss is 11011798.0 |  feature_var_mean is-0.9725422859191895\n",
      "亮度补偿 4.3\n",
      "16.25436440490336\n",
      "train_tps_Step：  20 | Reonstruction loss is 9287014.0  | Asmooth loss is  0.0 | Total loss is 9287014.0 |  feature_var_mean is-0.3037969172000885\n",
      "亮度补偿 4.3\n",
      "15.475937989061041\n",
      "train_tps_Step：  30 | Reonstruction loss is 8846033.0  | Asmooth loss is  0.0 | Total loss is 8846033.0 |  feature_var_mean is0.2657800018787384\n",
      "亮度补偿 4.3\n",
      "15.214604721227769\n",
      "train_tps_Step：  40 | Reonstruction loss is 8697107.0  | Asmooth loss is  0.0 | Total loss is 8697107.0 |  feature_var_mean is0.18756531178951263\n",
      "亮度补偿 4.3\n",
      "15.112145888578851\n",
      "train_tps_Step：  50 | Reonstruction loss is 8638899.0  | Asmooth loss is  0.0 | Total loss is 8638899.0 |  feature_var_mean is-0.07558746635913849\n",
      "亮度补偿 4.3\n",
      "15.077056013545542\n",
      "train_tps_Step：  60 | Reonstruction loss is 8619568.0  | Asmooth loss is  0.0 | Total loss is 8619568.0 |  feature_var_mean is-0.027322016656398773\n",
      "亮度补偿 4.3\n",
      "15.05486644330176\n",
      "train_tps_Step：  70 | Reonstruction loss is 8606347.0  | Asmooth loss is  0.0 | Total loss is 8606347.0 |  feature_var_mean is0.021298198029398918\n",
      "亮度补偿 4.3\n",
      "15.051021666562585\n",
      "train_tps_Step：  80 | Reonstruction loss is 8604201.0  | Asmooth loss is  0.0 | Total loss is 8604201.0 |  feature_var_mean is-0.002708864165470004\n",
      "亮度补偿 4.3\n",
      "15.051152871401122\n",
      "train_tps_Step：  90 | Reonstruction loss is 8604495.0  | Asmooth loss is  0.0 | Total loss is 8604495.0 |  feature_var_mean is-0.0026321648620069027\n",
      "亮度补偿 4.3\n",
      "15.04857292515861\n",
      "train_tps_Step： 100 | Reonstruction loss is 8602993.0  | Asmooth loss is  0.0 | Total loss is 8602993.0 |  feature_var_mean is0.001702108420431614\n",
      "亮度补偿 4.3\n",
      "15.04919535404422\n",
      "train_tps_Step： 110 | Reonstruction loss is 8603324.0  | Asmooth loss is  0.0 | Total loss is 8603324.0 |  feature_var_mean is-0.0005175542901270092\n",
      "亮度补偿 4.3\n",
      "15.048967349765022\n",
      "train_tps_Step： 120 | Reonstruction loss is 8603223.0  | Asmooth loss is  0.0 | Total loss is 8603223.0 |  feature_var_mean is0.00015708446153439581\n",
      "亮度补偿 4.3\n",
      "15.04916620793366\n",
      "train_tps_Step： 130 | Reonstruction loss is 8603357.0  | Asmooth loss is  0.0 | Total loss is 8603357.0 |  feature_var_mean is-0.0002158498828066513\n",
      "亮度补偿 4.3\n",
      "15.049034270463045\n",
      "train_tps_Step： 140 | Reonstruction loss is 8603259.0  | Asmooth loss is  0.0 | Total loss is 8603259.0 |  feature_var_mean is0.00011816501501016319\n",
      "亮度补偿 4.3\n",
      "15.049107634825594\n",
      "train_tps_Step： 150 | Reonstruction loss is 8603319.0  | Asmooth loss is  0.0 | Total loss is 8603319.0 |  feature_var_mean is-5.663394767907448e-05\n",
      "8603327.0\n",
      "z结束\n",
      "time spent 119.7548611164093 \n",
      "初始与终值的距离为:12.362605\n"
     ]
    }
   ],
   "source": [
    "#通过83.2训练出来的结果 4*5\n",
    "if __name__ == '__main__':\n",
    "    params = model_params(data_size=100,\n",
    "                              mini_batch_size=100,\n",
    "                              learning_rate=3e-1,\n",
    "                              total_epoch_num=np.int32(4000),\n",
    "                              outputdir=r'output',\n",
    "                              height=288,\n",
    "                              width=360,\n",
    "                              channel=3,\n",
    "      \n",
    "                              #cutTop=40,\n",
    "                              #cutBottom=0,\n",
    "                              #cutLeft=0,\n",
    "                              #cutRight=90,##248 270\n",
    "                          \n",
    "                              cutTop=44,\n",
    "                              cutBottom=44,\n",
    "                              cutLeft=6,\n",
    "                              cutRight=154,##248 270\n",
    "                              \n",
    "                              cPointRow=4,\n",
    "                              cPointCol=4\n",
    "                              )\n",
    "    #tps_base0 = np.loadtxt(r'A_val_real.txt').astype(np.float32)\n",
    "    #tps_base0 = np.loadtxt(r'TPS_matrix_constant.txt').astype(np.float32)\n",
    "    tps_base0 = np.load(r'groundtruth_z/tps_trained_.npy')\n",
    "    #tps_base0 = np.load(r'temp_A.npy')\n",
    "    #tps_base0 = np.load(r'output/temp_tps_trained_.npy')\n",
    "    #ids = range(1950,2000)\n",
    "    feature_in = 83.2 * np.ones([params.data_size, params.cPointRow * params.cPointCol, 1], dtype=np.float32)\n",
    "    #feature_in = np.load('groundtruth_z/disp_batch_invivo_z.npy')[0:20]\n",
    "    \n",
    "    #feature_in = 83.2 * np.random.normal(size=(params.data_size, params.cPointRow * params.cPointCol, 1))\n",
    "    \n",
    "    #feature_in = np.load('groundtruth_z/'+'feature_trained_final'+'.npy')[0:50,:,:]\n",
    "    #feature_in0 = np.load('groundtruth_z/feature_test.npy')\n",
    "    #feature_in0 = np.load('groundtruth_z/'+'feature_trained_final'+'.npy')\n",
    "    #print(feature_in0.shape)\n",
    "\n",
    "    #source_img_path = '/home/ubuntu/jupyter_workspace/dataset/guijiaoheart/phantom1_rect/'\n",
    "    source_img_path = '/home/ubuntu/jupyter_workspace/dataset/real_heart/invivo1_rect/'\n",
    "    #left_ims, right_ims = read_stereo_images(source_img_path, ids)\n",
    "    #train_z(params, feature_in, tps_base0, left_ims, right_ims, 'groundtruth_z/',1)\n",
    "    \n",
    "    loss = []\n",
    "    #alpha = 0.0001\n",
    "    alpha = 1.0\n",
    "    for i in range(0,1):\n",
    "        ids  = range(i*params.data_size,(i+1)*params.data_size)\n",
    "        left_ims, right_ims = read_stereo_images(source_img_path, ids)     \n",
    "        left_ims = np.array(left_ims, dtype = np.float32)\n",
    "        right_ims = np.array(right_ims, dtype = np.float32)\n",
    "        loss.append(train_z(params, feature_in, tps_base0, left_ims, right_ims, alpha,'output/',i, update_total=2))\n",
    "        \n",
    "    #np.save('output/'+ 'TPSloss_test_.npy', loss)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "标准TPS 4-10 219 209 257 235 208 274\n",
    "新方案  4-10 214 207 245 229 204 259\n",
    "97 99 67 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66960, 20)\n",
      "(83080, 20)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.load(r'tps_standard_248_270_4_5_inner.npy')\n",
    "b = np.loadtxt(r'TPS_matrix_constant.txt').astype(np.float32)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-3-c6133eff9a00>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-c6133eff9a00>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    int &b = a\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"stack_16:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_17:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_17:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_18:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_18:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_19:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_19:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_20:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_20:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_21:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_21:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_22:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_22:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_23:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_23:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_24:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_24:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_25:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_25:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_26:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_26:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_27:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_27:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_28:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_28:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_29:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_29:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_30:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_30:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_31:0\", shape=(16, 4), dtype=int32)\n",
      "Tensor(\"stack_31:0\", shape=(4, 4, 4), dtype=int32)\n",
      "Tensor(\"Reshape_32:0\", shape=(16, 4), dtype=int32)\n",
      "(16, 16, 4)\n",
      "[ 0 48 48  0]\n",
      "[[ 1.9082375   1.9006953   1.8930643  ...  0.0945636   0.09314096\n",
      "   0.09170604]\n",
      " [ 1.9006944   1.893203    1.8856256  ...  0.09078133  0.08937681\n",
      "   0.08796644]\n",
      " [ 1.8930638   1.8856261   1.8781009  ...  0.08704436  0.08566129\n",
      "   0.08427405]\n",
      " ...\n",
      " [ 0.09456718  0.0907855   0.08704567 ... -0.17719519 -0.1797899\n",
      "  -0.18240762]\n",
      " [ 0.09314442  0.08937824  0.08566511 ... -0.1797911  -0.18237865\n",
      "  -0.18501306]\n",
      " [ 0.09170926  0.08796906  0.0842762  ... -0.18240559 -0.18501055\n",
      "  -0.18761969]]\n",
      "[ 1.0000000e+00  0.0000000e+00  1.1920929e-06  1.0728836e-06\n",
      "  1.1920929e-07  1.1920929e-07  1.3113022e-06  2.2649765e-06\n",
      "  8.3446503e-07  1.7881393e-06  2.7418137e-06  2.2649765e-06\n",
      "  2.3841858e-07  2.3841858e-06  2.6226044e-06  3.3378601e-06\n",
      "  8.9406967e-07  9.9999964e-01 -1.3709068e-06 -7.1525574e-07\n",
      "  1.4901161e-06  1.1920929e-07 -1.0728836e-06 -1.3709068e-06\n",
      "  1.9073486e-06  1.7881393e-07  1.7881393e-06 -1.8477440e-06\n",
      "  4.2319298e-06  1.7881393e-07  4.1723251e-07 -3.5762787e-07\n",
      "  5.9604645e-07 -2.3841858e-07  9.9999988e-01  2.6226044e-06\n",
      " -1.4305115e-06 -1.1920929e-07  1.7881393e-06  3.4570694e-06\n",
      "  1.5497208e-06  2.0265579e-06  2.3841858e-07  3.9339066e-06\n",
      "  2.0265579e-06  4.7683716e-06  3.3378601e-06  5.1259995e-06\n",
      "  0.0000000e+00 -1.1920929e-06 -2.3841858e-07  9.9999833e-01\n",
      "  0.0000000e+00 -1.6689301e-06 -7.1525574e-07 -2.1457672e-06\n",
      "  1.1920929e-06 -7.1525574e-07  0.0000000e+00  4.7683716e-07\n",
      " -2.3841858e-06  0.0000000e+00  2.3841858e-07  0.0000000e+00\n",
      "  4.7683716e-07 -8.3446503e-07 -2.5033951e-06 -1.4305115e-06\n",
      "  9.9999940e-01 -7.7486038e-07 -1.9669533e-06 -5.7816505e-06\n",
      " -1.0132790e-06 -3.0398369e-06 -4.5895576e-06 -7.0929527e-06\n",
      " -7.7486038e-07 -3.8743019e-06 -5.6624413e-06 -6.8545341e-06\n",
      " -8.3446503e-07  1.1324883e-06  9.5367432e-07  2.0861626e-06\n",
      " -7.7486038e-07  1.0000007e+00  1.0728836e-06  3.6954880e-06\n",
      " -8.6426735e-07  9.8347664e-07 -1.5795231e-06  3.1292439e-06\n",
      " -1.2218952e-06 -8.9406967e-08 -2.0861626e-07  9.2387199e-07\n",
      "  1.9669533e-06  6.5565109e-07  1.0132790e-06  3.0398369e-06\n",
      "  3.5166740e-06 -7.7486038e-07  1.0000006e+00 -7.7486038e-07\n",
      "  1.6689301e-06  1.0728836e-06  1.1920929e-06 -4.7683716e-07\n",
      " -3.5762787e-07 -5.9604645e-07  8.3446503e-07  2.0265579e-06\n",
      "  1.1920929e-06  2.1457672e-06 -3.5166740e-06 -1.3113022e-06\n",
      " -2.3841858e-06  0.0000000e+00 -2.5629997e-06  9.9999988e-01\n",
      "  3.2186508e-06 -2.1457672e-06 -1.9073486e-06 -2.2649765e-06\n",
      "  5.1856041e-06  3.7550926e-06 -6.5565109e-07  5.3644180e-07\n",
      " -1.5497208e-06  7.1525574e-07  0.0000000e+00  2.5033951e-06\n",
      "  7.1525574e-07  1.1920929e-06 -1.9073486e-06  7.1525574e-07\n",
      "  9.9999887e-01  1.1920929e-07  1.9073486e-06  7.7486038e-06\n",
      " -1.9073486e-06  1.1920929e-06  0.0000000e+00  9.5367432e-07\n",
      "  2.3841858e-06 -2.3245811e-06 -2.9802322e-07 -1.0132790e-06\n",
      "  1.2516975e-06 -1.4305115e-06  1.0728836e-06 -3.4570694e-06\n",
      "  2.9802322e-07  9.9999917e-01  1.0132790e-06 -4.4703484e-06\n",
      "  8.3446503e-07 -5.9604645e-08  8.3446503e-07  1.2516975e-06\n",
      "  2.3841858e-07  1.5497208e-06 -1.1920929e-07 -1.5497208e-06\n",
      " -2.5033951e-06  3.5762787e-07 -2.2649765e-06 -1.1920929e-06\n",
      " -3.5762787e-07 -1.7881393e-06  9.9999774e-01  4.7683716e-07\n",
      "  2.0265579e-06 -8.3446503e-07 -8.3446503e-07  5.9604645e-07\n",
      " -2.7418137e-06 -3.9339066e-06  1.4305115e-06 -1.4305115e-06\n",
      "  4.2915344e-06 -1.9073486e-06 -1.5497208e-06 -1.7881393e-06\n",
      " -3.3378601e-06  3.6954880e-06 -1.4305115e-06  9.9999952e-01\n",
      "  0.0000000e+00 -8.3446503e-07  9.5367432e-07  5.9604645e-07\n",
      "  1.1920929e-06 -7.1525574e-07 -9.5367432e-07 -2.3841858e-06\n",
      " -1.9073486e-06 -1.1920929e-06  7.1525574e-07  1.9073486e-06\n",
      "  9.5367432e-07  1.6689301e-06  1.4305115e-06 -2.6226044e-06\n",
      "  1.0000019e+00  1.1920929e-06  2.1457672e-06  2.6226044e-06\n",
      " -3.0994415e-06  8.3446503e-07  2.8014183e-06  6.0200691e-06\n",
      "  4.1127205e-06  3.9339066e-06  3.0398369e-06 -8.9406967e-07\n",
      "  2.6226044e-06  1.1324883e-06  4.7683716e-07  5.0067902e-06\n",
      "  1.0132790e-06  1.0000014e+00  1.1920929e-06  2.3841858e-06\n",
      "  2.6226044e-06 -1.3113022e-06 -1.0728836e-06  8.3446503e-07\n",
      " -2.3841858e-07 -3.9339066e-06 -2.8610229e-06  2.9802322e-06\n",
      " -2.7418137e-06 -1.9073486e-06 -1.1920929e-07 -3.0994415e-06\n",
      "  1.1920929e-07 -1.5497208e-06  9.9999976e-01 -2.3841858e-07\n",
      "  1.6689301e-06  2.8610229e-06  7.1525574e-07 -9.5367432e-07\n",
      "  1.1920929e-06  3.3378601e-06  1.4305115e-06 -2.3841858e-06\n",
      "  2.8610229e-06  4.7683716e-07  1.1920929e-06  1.1920929e-06\n",
      "  1.4305115e-06  3.8146973e-06  4.7683716e-07  1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "##制作取点向量用于tf.gather，第三个损失函数\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def point_meshgrid(n):\n",
    "    w = 240\n",
    "    h = 240\n",
    "    control_num_u = 4\n",
    "    control_num_v = 4\n",
    "    \n",
    "    step_u = tf.cast(tf.floor(w / (control_num_u + 1)), tf.int32)####将一行分成n+1等分\n",
    "    step_v = tf.cast(tf.floor(h / (control_num_v + 1)), tf.int32)\n",
    "\n",
    "    edge_u_left = tf.cast(tf.floor(w % (control_num_u + 1) / 2), tf.int32)\n",
    "    edge_v_up = tf.cast(tf.floor(h % (control_num_v + 1) / 2), tf.int32)\n",
    "    edge_u_right = w % (control_num_u + 1) - edge_u_left\n",
    "    edge_v_low = h % (control_num_v + 1) - edge_v_up\n",
    "\n",
    "    range_start_u = edge_u_left + step_u\n",
    "    range_start_v = edge_v_up + step_v\n",
    "    range_end_u = w - edge_u_right - step_u\n",
    "    range_end_v = h - edge_v_low - step_v\n",
    "\n",
    "    control_u = tf.range(range_start_u, range_end_u + 1, delta=step_u)\n",
    "    control_v = tf.range(range_start_v, range_end_v + 1, delta=step_v)\n",
    "\n",
    "    c_u, c_v = tf.meshgrid(control_v, control_u)##扩展为栅格\n",
    "    \n",
    "    shape = tf.shape(c_u)\n",
    "    a = tf.zeros(shape,dtype = 'int32')\n",
    "    b = n*tf.ones(shape,dtype = 'int32')\n",
    "    \n",
    "    point_meshgrid_ = tf.stack([a,c_u,c_v,b],axis = 2)\n",
    "    print(point_meshgrid_)\n",
    "    point_meshgrid_ = tf.reshape(point_meshgrid_, [16,4])\n",
    "    print(point_meshgrid_)\n",
    "\n",
    "    return point_meshgrid_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "res = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(16):\n",
    "        point_meshgrid_ = sess.run(point_meshgrid(i))\n",
    "        res.append(point_meshgrid_)\n",
    "    res = np.array(res)\n",
    "    print(res.shape)\n",
    "    res = res.reshape(-1,4)\n",
    "    print(res[0])\n",
    "    \n",
    "    np.save('xymeshgrid.npy', res)\n",
    "    \n",
    "    tps_base0 = np.loadtxt(r'A_val_real.txt').astype(np.float32)\n",
    "    aa = tf.constant(tps_base0)\n",
    "    aa = tf.reshape(aa, [1,240,240,16])\n",
    "    bb = tf.gather_nd(aa,res)\n",
    "\n",
    "    print(sess.run(aa)[0,:,:,0])\n",
    "    print(sess.run(bb))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_12:0\", shape=(57600, 16), dtype=float32)\n",
      "1.9095305 -0.49275446\n",
      "0.20306881\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "matrix = np.load('./groundtruth_z//tps_trained.npy') #读入.npy文件\n",
    "tps_base0 = np.loadtxt(r'A_val_real.txt').astype(np.float32)\n",
    "\n",
    "a_loss = matrix - tps_base0\n",
    "\n",
    "aa = tf.constant(a_loss,dtype = 'float32')\n",
    "print(aa)\n",
    "\n",
    "bb = tf.transpose(aa,[1,0])\n",
    "bb = tf.reshape(bb, [16,240,240,1])\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    filter_ = np.array([[0,1,0],[1,-4,1],[0,1,0]]).reshape(3,3,1,1)###3*3,输入3通道，输出3通道\n",
    "    \n",
    "    \n",
    "    filter_1 = tf.constant(filter_,dtype = 'float32')\n",
    "    Laplace_img = tf.nn.conv2d(input = bb,filter = filter_1,strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    loss_A_smooth = tf.reduce_sum(tf.square(Laplace_img))\n",
    "    \n",
    "    dd = sess.run(bb)\n",
    "    print(matrix.max(), matrix.min())\n",
    "    \n",
    "    #print(sess.run(Laplace_img))\n",
    "    print(sess.run(loss_A_smooth))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/py36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.4]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    " \n",
    "input1 = tf.placeholder(tf.float32,shape = (2,1))\n",
    "input2 = tf.placeholder(tf.float32)\n",
    " \n",
    "output = tf.multiply(input1[0], input2)\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(output, feed_dict = {input1:[[2.0],[3.0]], input2: 3.2}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
