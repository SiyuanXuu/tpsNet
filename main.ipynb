{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard TPS training Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model TPS\n",
      "T_init.shape=(40000, 16)\n",
      "Saved T_init at file : output/T_init.txt\n",
      "load T matrix from output/T_init.txt\n",
      "--------- Epoch 0 ---------\n",
      "iter   0 | Recons loss=137.8087921142578 | theta_var_mean= 0.0\n",
      "iter  10 | Recons loss=144.69595336914062 | theta_var_mean=-0.39304596185684204\n",
      "iter  20 | Recons loss=93.77085876464844 | theta_var_mean=-0.11006345599889755\n",
      "cost time:9.310243129730225 s\n",
      "Epoch 0 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 1 ---------\n",
      "iter   0 | Recons loss=138.94943237304688 | theta_var_mean=0.08138217777013779\n",
      "iter  10 | Recons loss=78.22169494628906 | theta_var_mean=-0.1689646691083908\n",
      "iter  20 | Recons loss=92.41341400146484 | theta_var_mean=-0.42123356461524963\n",
      "cost time:5.427545547485352 s\n",
      "Epoch 1 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 2 ---------\n",
      "iter   0 | Recons loss=121.13221740722656 | theta_var_mean=0.06545872986316681\n",
      "iter  10 | Recons loss=85.420654296875 | theta_var_mean=-0.23672476410865784\n",
      "iter  20 | Recons loss=91.62653350830078 | theta_var_mean=-0.46339353919029236\n",
      "cost time:5.463226795196533 s\n",
      "Epoch 2 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 3 ---------\n",
      "iter   0 | Recons loss=124.75521087646484 | theta_var_mean=0.06635227054357529\n",
      "iter  10 | Recons loss=84.4874038696289 | theta_var_mean=-0.23845729231834412\n",
      "iter  20 | Recons loss=91.81153869628906 | theta_var_mean=-0.46727102994918823\n",
      "cost time:5.494675159454346 s\n",
      "Epoch 3 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 4 ---------\n",
      "iter   0 | Recons loss=124.01493072509766 | theta_var_mean=0.06628217548131943\n",
      "iter  10 | Recons loss=84.6390151977539 | theta_var_mean=-0.24289341270923615\n",
      "iter  20 | Recons loss=91.83473205566406 | theta_var_mean=-0.47207188606262207\n",
      "cost time:5.419133901596069 s\n",
      "Epoch 4 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 5 ---------\n",
      "iter   0 | Recons loss=124.16276550292969 | theta_var_mean=0.06656789779663086\n",
      "iter  10 | Recons loss=84.63331604003906 | theta_var_mean=-0.24289456009864807\n",
      "iter  20 | Recons loss=91.8366470336914 | theta_var_mean=-0.4721511900424957\n",
      "cost time:5.453872442245483 s\n",
      "Epoch 5 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 6 ---------\n",
      "iter   0 | Recons loss=124.19129943847656 | theta_var_mean=0.06659569591283798\n",
      "iter  10 | Recons loss=84.63941955566406 | theta_var_mean=-0.2459692507982254\n",
      "iter  20 | Recons loss=91.83219146728516 | theta_var_mean=-0.47658175230026245\n",
      "cost time:5.492239713668823 s\n",
      "Epoch 6 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 7 ---------\n",
      "iter   0 | Recons loss=124.1781234741211 | theta_var_mean=0.06668210029602051\n",
      "iter  10 | Recons loss=84.64933776855469 | theta_var_mean=-0.24566388130187988\n",
      "iter  20 | Recons loss=91.86463928222656 | theta_var_mean=-0.4754692018032074\n",
      "cost time:5.392155885696411 s\n",
      "Epoch 7 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 8 ---------\n",
      "iter   0 | Recons loss=124.2265853881836 | theta_var_mean=0.06675472110509872\n",
      "iter  10 | Recons loss=84.65291595458984 | theta_var_mean=-0.24758124351501465\n",
      "iter  20 | Recons loss=91.8492202758789 | theta_var_mean=-0.47811850905418396\n",
      "cost time:5.461091756820679 s\n",
      "Epoch 8 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 9 ---------\n",
      "iter   0 | Recons loss=124.2093276977539 | theta_var_mean=0.06679554283618927\n",
      "iter  10 | Recons loss=84.66271209716797 | theta_var_mean=-0.24740520119667053\n",
      "iter  20 | Recons loss=91.88005828857422 | theta_var_mean=-0.47740674018859863\n",
      "cost time:5.4619269371032715 s\n",
      "Epoch 9 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 10 ---------\n",
      "iter   0 | Recons loss=124.23744201660156 | theta_var_mean=0.066830113530159\n",
      "iter  10 | Recons loss=84.65480041503906 | theta_var_mean=-0.24832458794116974\n",
      "iter  20 | Recons loss=91.85676574707031 | theta_var_mean=-0.4788687825202942\n",
      "cost time:5.419078350067139 s\n",
      "Epoch 10 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 11 ---------\n",
      "iter   0 | Recons loss=124.21788024902344 | theta_var_mean=0.06685404479503632\n",
      "iter  10 | Recons loss=84.66565704345703 | theta_var_mean=-0.24788565933704376\n",
      "iter  20 | Recons loss=91.87950134277344 | theta_var_mean=-0.4776591360569\n",
      "cost time:5.515181303024292 s\n",
      "Epoch 11 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 12 ---------\n",
      "iter   0 | Recons loss=124.25370788574219 | theta_var_mean=0.06685075908899307\n",
      "iter  10 | Recons loss=84.65862274169922 | theta_var_mean=-0.24907270073890686\n",
      "iter  20 | Recons loss=91.86519622802734 | theta_var_mean=-0.47969216108322144\n",
      "cost time:5.480974435806274 s\n",
      "Epoch 12 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 13 ---------\n",
      "iter   0 | Recons loss=124.23551940917969 | theta_var_mean=0.0669102668762207\n",
      "iter  10 | Recons loss=84.67000579833984 | theta_var_mean=-0.2483675479888916\n",
      "iter  20 | Recons loss=91.88421630859375 | theta_var_mean=-0.47827768325805664\n",
      "cost time:5.397604465484619 s\n",
      "Epoch 13 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 14 ---------\n",
      "iter   0 | Recons loss=124.2571792602539 | theta_var_mean=0.06686945259571075\n",
      "iter  10 | Recons loss=84.65714263916016 | theta_var_mean=-0.2495153397321701\n",
      "iter  20 | Recons loss=91.86778259277344 | theta_var_mean=-0.4800416827201843\n",
      "cost time:5.467328786849976 s\n",
      "Epoch 14 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 15 ---------\n",
      "iter   0 | Recons loss=124.24822998046875 | theta_var_mean=0.06690988689661026\n",
      "iter  10 | Recons loss=84.67312622070312 | theta_var_mean=-0.2490718811750412\n",
      "iter  20 | Recons loss=91.88816833496094 | theta_var_mean=-0.47883400321006775\n",
      "cost time:5.482423543930054 s\n",
      "Epoch 15 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 16 ---------\n",
      "iter   0 | Recons loss=124.26773834228516 | theta_var_mean=0.0668824166059494\n",
      "iter  10 | Recons loss=84.66221618652344 | theta_var_mean=-0.2502020299434662\n",
      "iter  20 | Recons loss=91.87313842773438 | theta_var_mean=-0.4805753231048584\n",
      "cost time:5.425982475280762 s\n",
      "Epoch 16 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 17 ---------\n",
      "iter   0 | Recons loss=124.25479888916016 | theta_var_mean=0.06695237010717392\n",
      "iter  10 | Recons loss=84.67539978027344 | theta_var_mean=-0.24947114288806915\n",
      "iter  20 | Recons loss=91.89142608642578 | theta_var_mean=-0.4793989658355713\n",
      "cost time:5.479283809661865 s\n",
      "Epoch 17 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 18 ---------\n",
      "iter   0 | Recons loss=124.27619934082031 | theta_var_mean=0.06693148612976074\n",
      "iter  10 | Recons loss=84.66218566894531 | theta_var_mean=-0.25019869208335876\n",
      "iter  20 | Recons loss=91.87397766113281 | theta_var_mean=-0.4807074964046478\n",
      "cost time:5.506886959075928 s\n",
      "Epoch 18 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 19 ---------\n",
      "iter   0 | Recons loss=124.26029968261719 | theta_var_mean=0.06694803386926651\n",
      "iter  10 | Recons loss=84.67578887939453 | theta_var_mean=-0.24974742531776428\n",
      "iter  20 | Recons loss=91.89559173583984 | theta_var_mean=-0.4797379970550537\n",
      "cost time:5.42989444732666 s\n",
      "Epoch 19 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 20 ---------\n",
      "iter   0 | Recons loss=124.27629089355469 | theta_var_mean=0.06693696975708008\n",
      "iter  10 | Recons loss=84.66462707519531 | theta_var_mean=-0.24998688697814941\n",
      "iter  20 | Recons loss=91.87602233886719 | theta_var_mean=-0.4803573489189148\n",
      "cost time:5.461353778839111 s\n",
      "Epoch 20 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 21 ---------\n",
      "iter   0 | Recons loss=124.25943756103516 | theta_var_mean=0.06694302707910538\n",
      "iter  10 | Recons loss=84.67579650878906 | theta_var_mean=-0.25005286931991577\n",
      "iter  20 | Recons loss=91.89545440673828 | theta_var_mean=-0.47996944189071655\n",
      "cost time:5.476350784301758 s\n",
      "Epoch 21 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 22 ---------\n",
      "iter   0 | Recons loss=124.28153228759766 | theta_var_mean=0.06693840026855469\n",
      "iter  10 | Recons loss=84.66688537597656 | theta_var_mean=-0.2502479553222656\n",
      "iter  20 | Recons loss=91.87837219238281 | theta_var_mean=-0.48076337575912476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time:5.46565318107605 s\n",
      "Epoch 22 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 23 ---------\n",
      "iter   0 | Recons loss=124.25975036621094 | theta_var_mean=0.06695923954248428\n",
      "iter  10 | Recons loss=84.68107604980469 | theta_var_mean=-0.2501850128173828\n",
      "iter  20 | Recons loss=91.89222717285156 | theta_var_mean=-0.479966402053833\n",
      "cost time:5.441790342330933 s\n",
      "Epoch 23 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 24 ---------\n",
      "iter   0 | Recons loss=124.28544616699219 | theta_var_mean=0.06696295738220215\n",
      "iter  10 | Recons loss=84.66627502441406 | theta_var_mean=-0.25053995847702026\n",
      "iter  20 | Recons loss=91.87973022460938 | theta_var_mean=-0.4809950888156891\n",
      "cost time:5.485462665557861 s\n",
      "Epoch 24 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 25 ---------\n",
      "iter   0 | Recons loss=124.26634216308594 | theta_var_mean=0.06697263568639755\n",
      "iter  10 | Recons loss=84.67857360839844 | theta_var_mean=-0.2503240704536438\n",
      "iter  20 | Recons loss=91.89569091796875 | theta_var_mean=-0.4803706109523773\n",
      "cost time:5.415887832641602 s\n",
      "Epoch 25 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 26 ---------\n",
      "iter   0 | Recons loss=124.28752136230469 | theta_var_mean=0.06696844100952148\n",
      "iter  10 | Recons loss=84.6689453125 | theta_var_mean=-0.25071272253990173\n",
      "iter  20 | Recons loss=91.88028717041016 | theta_var_mean=-0.4809860587120056\n",
      "cost time:5.456451177597046 s\n",
      "Epoch 26 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 27 ---------\n",
      "iter   0 | Recons loss=124.27177429199219 | theta_var_mean=0.06698079407215118\n",
      "iter  10 | Recons loss=84.6806411743164 | theta_var_mean=-0.25063496828079224\n",
      "iter  20 | Recons loss=91.89665222167969 | theta_var_mean=-0.48070430755615234\n",
      "cost time:5.470017671585083 s\n",
      "Epoch 27 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 28 ---------\n",
      "iter   0 | Recons loss=124.28963470458984 | theta_var_mean=0.06699252128601074\n",
      "iter  10 | Recons loss=84.66984558105469 | theta_var_mean=-0.25059980154037476\n",
      "iter  20 | Recons loss=91.88055419921875 | theta_var_mean=-0.48115015029907227\n",
      "cost time:5.422319173812866 s\n",
      "Epoch 28 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 29 ---------\n",
      "iter   0 | Recons loss=124.2715835571289 | theta_var_mean=0.06697192043066025\n",
      "iter  10 | Recons loss=84.68013763427734 | theta_var_mean=-0.25069156289100647\n",
      "iter  20 | Recons loss=91.89738464355469 | theta_var_mean=-0.4806344509124756\n",
      "cost time:5.446802139282227 s\n",
      "Epoch 29 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 30 ---------\n",
      "iter   0 | Recons loss=124.29182434082031 | theta_var_mean=0.06699347496032715\n",
      "iter  10 | Recons loss=84.66943359375 | theta_var_mean=-0.2508293688297272\n",
      "iter  20 | Recons loss=91.88219451904297 | theta_var_mean=-0.4813117980957031\n",
      "cost time:5.516136884689331 s\n",
      "Epoch 30 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 31 ---------\n",
      "iter   0 | Recons loss=124.27644348144531 | theta_var_mean=0.06698064506053925\n",
      "iter  10 | Recons loss=84.67752838134766 | theta_var_mean=-0.25066858530044556\n",
      "iter  20 | Recons loss=91.89850616455078 | theta_var_mean=-0.4807892441749573\n",
      "cost time:5.409978628158569 s\n",
      "Epoch 31 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 32 ---------\n",
      "iter   0 | Recons loss=124.29450988769531 | theta_var_mean=0.06699414551258087\n",
      "iter  10 | Recons loss=84.6705322265625 | theta_var_mean=-0.2509220540523529\n",
      "iter  20 | Recons loss=91.88223266601562 | theta_var_mean=-0.4814949631690979\n",
      "cost time:5.518372058868408 s\n",
      "Epoch 32 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 33 ---------\n",
      "iter   0 | Recons loss=124.2743148803711 | theta_var_mean=0.066999152302742\n",
      "iter  10 | Recons loss=84.6802749633789 | theta_var_mean=-0.25060248374938965\n",
      "iter  20 | Recons loss=91.898681640625 | theta_var_mean=-0.4806271195411682\n",
      "cost time:5.523833990097046 s\n",
      "Epoch 33 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 34 ---------\n",
      "iter   0 | Recons loss=124.29862213134766 | theta_var_mean=0.06699128448963165\n",
      "iter  10 | Recons loss=84.67192077636719 | theta_var_mean=-0.2509300112724304\n",
      "iter  20 | Recons loss=91.88179779052734 | theta_var_mean=-0.4815830588340759\n",
      "cost time:5.466894626617432 s\n",
      "Epoch 34 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 35 ---------\n",
      "iter   0 | Recons loss=124.27850341796875 | theta_var_mean=0.06698618084192276\n",
      "iter  10 | Recons loss=84.68182373046875 | theta_var_mean=-0.2506450116634369\n",
      "iter  20 | Recons loss=91.90015411376953 | theta_var_mean=-0.4807215631008148\n",
      "cost time:5.443052768707275 s\n",
      "Epoch 35 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 36 ---------\n",
      "iter   0 | Recons loss=124.29795837402344 | theta_var_mean=0.06699347496032715\n",
      "iter  10 | Recons loss=84.67204284667969 | theta_var_mean=-0.2512461543083191\n",
      "iter  20 | Recons loss=91.88186645507812 | theta_var_mean=-0.481719434261322\n",
      "cost time:5.48461127281189 s\n",
      "Epoch 36 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 37 ---------\n",
      "iter   0 | Recons loss=124.2807388305664 | theta_var_mean=0.06700806319713593\n",
      "iter  10 | Recons loss=84.68132781982422 | theta_var_mean=-0.25096163153648376\n",
      "iter  20 | Recons loss=91.8980712890625 | theta_var_mean=-0.48105183243751526\n",
      "cost time:5.371938943862915 s\n",
      "Epoch 37 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 38 ---------\n",
      "iter   0 | Recons loss=124.29841613769531 | theta_var_mean=0.06700034439563751\n",
      "iter  10 | Recons loss=84.67342376708984 | theta_var_mean=-0.25119227170944214\n",
      "iter  20 | Recons loss=91.88291931152344 | theta_var_mean=-0.48180270195007324\n",
      "cost time:5.477839946746826 s\n",
      "Epoch 38 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 39 ---------\n",
      "iter   0 | Recons loss=124.2823486328125 | theta_var_mean=0.06700129806995392\n",
      "iter  10 | Recons loss=84.68230438232422 | theta_var_mean=-0.2507952153682709\n",
      "iter  20 | Recons loss=91.89694213867188 | theta_var_mean=-0.48087558150291443\n",
      "cost time:5.4705400466918945 s\n",
      "Epoch 39 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 40 ---------\n",
      "iter   0 | Recons loss=124.29817199707031 | theta_var_mean=0.06699180603027344\n",
      "iter  10 | Recons loss=84.67327880859375 | theta_var_mean=-0.25111857056617737\n",
      "iter  20 | Recons loss=91.8839111328125 | theta_var_mean=-0.48160141706466675\n",
      "cost time:5.434516429901123 s\n",
      "Epoch 40 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 41 ---------\n",
      "iter   0 | Recons loss=124.28233337402344 | theta_var_mean=0.06700010597705841\n",
      "iter  10 | Recons loss=84.68455505371094 | theta_var_mean=-0.25115150213241577\n",
      "iter  20 | Recons loss=91.89706420898438 | theta_var_mean=-0.4810439646244049\n",
      "cost time:5.4476542472839355 s\n",
      "Epoch 41 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 42 ---------\n",
      "iter   0 | Recons loss=124.29959869384766 | theta_var_mean=0.06700768321752548\n",
      "iter  10 | Recons loss=84.6730728149414 | theta_var_mean=-0.25150197744369507\n",
      "iter  20 | Recons loss=91.88499450683594 | theta_var_mean=-0.482023149728775\n",
      "cost time:5.459566354751587 s\n",
      "Epoch 42 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 43 ---------\n",
      "iter   0 | Recons loss=124.28401947021484 | theta_var_mean=0.06701187789440155\n",
      "iter  10 | Recons loss=84.68329620361328 | theta_var_mean=-0.2510261535644531\n",
      "iter  20 | Recons loss=91.89796447753906 | theta_var_mean=-0.4810279309749603\n",
      "cost time:5.424444198608398 s\n",
      "Epoch 43 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 44 ---------\n",
      "iter   0 | Recons loss=124.29842376708984 | theta_var_mean=0.06699981540441513\n",
      "iter  10 | Recons loss=84.673828125 | theta_var_mean=-0.25134000182151794\n",
      "iter  20 | Recons loss=91.88448333740234 | theta_var_mean=-0.48186764121055603\n",
      "cost time:5.4872636795043945 s\n",
      "Epoch 44 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 45 ---------\n",
      "iter   0 | Recons loss=124.28155517578125 | theta_var_mean=0.06700243800878525\n",
      "iter  10 | Recons loss=84.68415069580078 | theta_var_mean=-0.2509062886238098\n",
      "iter  20 | Recons loss=91.90045166015625 | theta_var_mean=-0.48080429434776306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time:5.504762887954712 s\n",
      "Epoch 45 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 46 ---------\n",
      "iter   0 | Recons loss=124.2984619140625 | theta_var_mean=0.0669768825173378\n",
      "iter  10 | Recons loss=84.6763916015625 | theta_var_mean=-0.2520577311515808\n",
      "iter  20 | Recons loss=91.88502502441406 | theta_var_mean=-0.4823625087738037\n",
      "cost time:5.432217836380005 s\n",
      "Epoch 46 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 47 ---------\n",
      "iter   0 | Recons loss=124.28448486328125 | theta_var_mean=0.06703510135412216\n",
      "iter  10 | Recons loss=84.68324279785156 | theta_var_mean=-0.2510698437690735\n",
      "iter  20 | Recons loss=91.89815521240234 | theta_var_mean=-0.48103123903274536\n",
      "cost time:5.477051734924316 s\n",
      "Epoch 47 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 48 ---------\n",
      "iter   0 | Recons loss=124.3001937866211 | theta_var_mean=0.066989466547966\n",
      "iter  10 | Recons loss=84.67752075195312 | theta_var_mean=-0.2517894208431244\n",
      "iter  20 | Recons loss=91.88331604003906 | theta_var_mean=-0.48197174072265625\n",
      "cost time:5.4699273109436035 s\n",
      "Epoch 48 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 49 ---------\n",
      "iter   0 | Recons loss=124.28609466552734 | theta_var_mean=0.06702180206775665\n",
      "iter  10 | Recons loss=84.6837158203125 | theta_var_mean=-0.25125569105148315\n",
      "iter  20 | Recons loss=91.90084075927734 | theta_var_mean=-0.48138508200645447\n",
      "cost time:5.3984386920928955 s\n",
      "Epoch 49 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 50 ---------\n",
      "iter   0 | Recons loss=124.3013687133789 | theta_var_mean=0.06700257956981659\n",
      "iter  10 | Recons loss=84.67623138427734 | theta_var_mean=-0.25138765573501587\n",
      "iter  20 | Recons loss=91.8840103149414 | theta_var_mean=-0.4816182255744934\n",
      "cost time:5.464282274246216 s\n",
      "Epoch 50 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 51 ---------\n",
      "iter   0 | Recons loss=124.2872085571289 | theta_var_mean=0.0670042484998703\n",
      "iter  10 | Recons loss=84.68327331542969 | theta_var_mean=-0.25151586532592773\n",
      "iter  20 | Recons loss=91.90005493164062 | theta_var_mean=-0.481461763381958\n",
      "cost time:5.422555208206177 s\n",
      "Epoch 51 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 52 ---------\n",
      "iter   0 | Recons loss=124.29963684082031 | theta_var_mean=0.06700949370861053\n",
      "iter  10 | Recons loss=84.67720031738281 | theta_var_mean=-0.2518211007118225\n",
      "iter  20 | Recons loss=91.88340759277344 | theta_var_mean=-0.48212680220603943\n",
      "cost time:5.447744369506836 s\n",
      "Epoch 52 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 53 ---------\n",
      "iter   0 | Recons loss=124.28489685058594 | theta_var_mean=0.0670197457075119\n",
      "iter  10 | Recons loss=84.6858901977539 | theta_var_mean=-0.2513613700866699\n",
      "iter  20 | Recons loss=91.90052795410156 | theta_var_mean=-0.48121723532676697\n",
      "cost time:5.564381837844849 s\n",
      "Epoch 53 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 54 ---------\n",
      "iter   0 | Recons loss=124.30228424072266 | theta_var_mean=0.0670083537697792\n",
      "iter  10 | Recons loss=84.6732406616211 | theta_var_mean=-0.25166305899620056\n",
      "iter  20 | Recons loss=91.88986206054688 | theta_var_mean=-0.48196226358413696\n",
      "cost time:5.498173236846924 s\n",
      "Epoch 54 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 55 ---------\n",
      "iter   0 | Recons loss=124.28807067871094 | theta_var_mean=0.06701560318470001\n",
      "iter  10 | Recons loss=84.6854248046875 | theta_var_mean=-0.25121989846229553\n",
      "iter  20 | Recons loss=91.90035247802734 | theta_var_mean=-0.4812853932380676\n",
      "cost time:5.498462200164795 s\n",
      "Epoch 55 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 56 ---------\n",
      "iter   0 | Recons loss=124.3024673461914 | theta_var_mean=0.06701292842626572\n",
      "iter  10 | Recons loss=84.67466735839844 | theta_var_mean=-0.2518995702266693\n",
      "iter  20 | Recons loss=91.88735961914062 | theta_var_mean=-0.48205727338790894\n",
      "cost time:5.487569808959961 s\n",
      "Epoch 56 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 57 ---------\n",
      "iter   0 | Recons loss=124.2871322631836 | theta_var_mean=0.06701531261205673\n",
      "iter  10 | Recons loss=84.68484497070312 | theta_var_mean=-0.251554399728775\n",
      "iter  20 | Recons loss=91.90113067626953 | theta_var_mean=-0.48156872391700745\n",
      "cost time:5.491606950759888 s\n",
      "Epoch 57 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 58 ---------\n",
      "iter   0 | Recons loss=124.3017349243164 | theta_var_mean=0.06701912730932236\n",
      "iter  10 | Recons loss=84.67684173583984 | theta_var_mean=-0.25191131234169006\n",
      "iter  20 | Recons loss=91.88533020019531 | theta_var_mean=-0.48211726546287537\n",
      "cost time:5.428028583526611 s\n",
      "Epoch 58 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 59 ---------\n",
      "iter   0 | Recons loss=124.2889633178711 | theta_var_mean=0.06703801453113556\n",
      "iter  10 | Recons loss=84.68455505371094 | theta_var_mean=-0.25152191519737244\n",
      "iter  20 | Recons loss=91.89881896972656 | theta_var_mean=-0.4815455377101898\n",
      "cost time:5.474188327789307 s\n",
      "Epoch 59 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 60 ---------\n",
      "iter   0 | Recons loss=124.3013916015625 | theta_var_mean=0.06701426208019257\n",
      "iter  10 | Recons loss=84.67857360839844 | theta_var_mean=-0.2519073486328125\n",
      "iter  20 | Recons loss=91.8841552734375 | theta_var_mean=-0.4821456968784332\n",
      "cost time:5.4897236824035645 s\n",
      "Epoch 60 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 61 ---------\n",
      "iter   0 | Recons loss=124.28736877441406 | theta_var_mean=0.0670173168182373\n",
      "iter  10 | Recons loss=84.68594360351562 | theta_var_mean=-0.2512431740760803\n",
      "iter  20 | Recons loss=91.90248107910156 | theta_var_mean=-0.48113852739334106\n",
      "cost time:5.399834871292114 s\n",
      "Epoch 61 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 62 ---------\n",
      "iter   0 | Recons loss=124.30339050292969 | theta_var_mean=0.0670003890991211\n",
      "iter  10 | Recons loss=84.67620086669922 | theta_var_mean=-0.2518162727355957\n",
      "iter  20 | Recons loss=91.88603210449219 | theta_var_mean=-0.48208069801330566\n",
      "cost time:5.471563339233398 s\n",
      "Epoch 62 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 63 ---------\n",
      "iter   0 | Recons loss=124.28749084472656 | theta_var_mean=0.06701059639453888\n",
      "iter  10 | Recons loss=84.68571472167969 | theta_var_mean=-0.2515377104282379\n",
      "iter  20 | Recons loss=91.90046691894531 | theta_var_mean=-0.4813272953033447\n",
      "cost time:5.490546941757202 s\n",
      "Epoch 63 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 64 ---------\n",
      "iter   0 | Recons loss=124.30369567871094 | theta_var_mean=0.06701011955738068\n",
      "iter  10 | Recons loss=84.67748260498047 | theta_var_mean=-0.25207704305648804\n",
      "iter  20 | Recons loss=91.88607025146484 | theta_var_mean=-0.4823082387447357\n",
      "cost time:5.4318976402282715 s\n",
      "Epoch 64 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 65 ---------\n",
      "iter   0 | Recons loss=124.28987121582031 | theta_var_mean=0.06701812893152237\n",
      "iter  10 | Recons loss=84.68563842773438 | theta_var_mean=-0.2515348792076111\n",
      "iter  20 | Recons loss=91.90470886230469 | theta_var_mean=-0.4814012944698334\n",
      "cost time:5.453304767608643 s\n",
      "Epoch 65 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 66 ---------\n",
      "iter   0 | Recons loss=124.30216979980469 | theta_var_mean=0.06700582802295685\n",
      "iter  10 | Recons loss=84.6771240234375 | theta_var_mean=-0.2519180178642273\n",
      "iter  20 | Recons loss=91.88407897949219 | theta_var_mean=-0.4821999967098236\n",
      "cost time:5.522183418273926 s\n",
      "Epoch 66 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 67 ---------\n",
      "iter   0 | Recons loss=124.2876968383789 | theta_var_mean=0.06701865047216415\n",
      "iter  10 | Recons loss=84.6852798461914 | theta_var_mean=-0.25127291679382324\n",
      "iter  20 | Recons loss=91.90275573730469 | theta_var_mean=-0.48112934827804565\n",
      "cost time:5.382583856582642 s\n",
      "Epoch 67 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 68 ---------\n",
      "iter   0 | Recons loss=124.30387878417969 | theta_var_mean=0.06700577586889267\n",
      "iter  10 | Recons loss=84.67862701416016 | theta_var_mean=-0.2522580623626709\n",
      "iter  20 | Recons loss=91.88523864746094 | theta_var_mean=-0.4824364185333252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time:5.457496881484985 s\n",
      "Epoch 68 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 69 ---------\n",
      "iter   0 | Recons loss=124.29032897949219 | theta_var_mean=0.06702518463134766\n",
      "iter  10 | Recons loss=84.68418884277344 | theta_var_mean=-0.251512348651886\n",
      "iter  20 | Recons loss=91.90379333496094 | theta_var_mean=-0.4813517928123474\n",
      "cost time:5.483031749725342 s\n",
      "Epoch 69 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 70 ---------\n",
      "iter   0 | Recons loss=124.300048828125 | theta_var_mean=0.0670098289847374\n",
      "iter  10 | Recons loss=84.67689514160156 | theta_var_mean=-0.25213560461997986\n",
      "iter  20 | Recons loss=91.88624572753906 | theta_var_mean=-0.4824378490447998\n",
      "cost time:5.412936210632324 s\n",
      "Epoch 70 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 71 ---------\n",
      "iter   0 | Recons loss=124.2902603149414 | theta_var_mean=0.06702146679162979\n",
      "iter  10 | Recons loss=84.68611145019531 | theta_var_mean=-0.2512827515602112\n",
      "iter  20 | Recons loss=91.9012680053711 | theta_var_mean=-0.48111265897750854\n",
      "cost time:5.482988119125366 s\n",
      "Epoch 71 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 72 ---------\n",
      "iter   0 | Recons loss=124.3033447265625 | theta_var_mean=0.0670037716627121\n",
      "iter  10 | Recons loss=84.67701721191406 | theta_var_mean=-0.25202351808547974\n",
      "iter  20 | Recons loss=91.8875732421875 | theta_var_mean=-0.4823794364929199\n",
      "cost time:5.511146306991577 s\n",
      "Epoch 72 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 73 ---------\n",
      "iter   0 | Recons loss=124.28739929199219 | theta_var_mean=0.06701769679784775\n",
      "iter  10 | Recons loss=84.68620300292969 | theta_var_mean=-0.2515571117401123\n",
      "iter  20 | Recons loss=91.89850616455078 | theta_var_mean=-0.48120513558387756\n",
      "cost time:5.402576208114624 s\n",
      "Epoch 73 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 74 ---------\n",
      "iter   0 | Recons loss=124.30574035644531 | theta_var_mean=0.06701669842004776\n",
      "iter  10 | Recons loss=84.67622375488281 | theta_var_mean=-0.2522955536842346\n",
      "iter  20 | Recons loss=91.88780212402344 | theta_var_mean=-0.48267993330955505\n",
      "cost time:5.496734142303467 s\n",
      "Epoch 74 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 75 ---------\n",
      "iter   0 | Recons loss=124.29045104980469 | theta_var_mean=0.06702146679162979\n",
      "iter  10 | Recons loss=84.68621063232422 | theta_var_mean=-0.25142210721969604\n",
      "iter  20 | Recons loss=91.90331268310547 | theta_var_mean=-0.48113909363746643\n",
      "cost time:5.4596312046051025 s\n",
      "Epoch 75 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 76 ---------\n",
      "iter   0 | Recons loss=124.3023910522461 | theta_var_mean=0.0670105442404747\n",
      "iter  10 | Recons loss=84.67669677734375 | theta_var_mean=-0.25218144059181213\n",
      "iter  20 | Recons loss=91.88424682617188 | theta_var_mean=-0.48256054520606995\n",
      "cost time:5.438405990600586 s\n",
      "Epoch 76 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 77 ---------\n",
      "iter   0 | Recons loss=124.28936767578125 | theta_var_mean=0.06700916588306427\n",
      "iter  10 | Recons loss=84.68666076660156 | theta_var_mean=-0.25131940841674805\n",
      "iter  20 | Recons loss=91.9048080444336 | theta_var_mean=-0.4810788631439209\n",
      "cost time:5.488899230957031 s\n",
      "Epoch 77 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 78 ---------\n",
      "iter   0 | Recons loss=124.30598449707031 | theta_var_mean=0.06700997054576874\n",
      "iter  10 | Recons loss=84.67691040039062 | theta_var_mean=-0.25233569741249084\n",
      "iter  20 | Recons loss=91.88307189941406 | theta_var_mean=-0.482536643743515\n",
      "cost time:5.520464181900024 s\n",
      "Epoch 78 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 79 ---------\n",
      "iter   0 | Recons loss=124.28829193115234 | theta_var_mean=0.06701846420764923\n",
      "iter  10 | Recons loss=84.68579864501953 | theta_var_mean=-0.2515619695186615\n",
      "iter  20 | Recons loss=91.90316772460938 | theta_var_mean=-0.4812909960746765\n",
      "cost time:5.425267219543457 s\n",
      "Epoch 79 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 80 ---------\n",
      "iter   0 | Recons loss=124.30501556396484 | theta_var_mean=0.06701874732971191\n",
      "iter  10 | Recons loss=84.6771469116211 | theta_var_mean=-0.25236672163009644\n",
      "iter  20 | Recons loss=91.88691711425781 | theta_var_mean=-0.4827088713645935\n",
      "cost time:5.469156265258789 s\n",
      "Epoch 80 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 81 ---------\n",
      "iter   0 | Recons loss=124.2906723022461 | theta_var_mean=0.06702671200037003\n",
      "iter  10 | Recons loss=84.68610382080078 | theta_var_mean=-0.2513115406036377\n",
      "iter  20 | Recons loss=91.90174865722656 | theta_var_mean=-0.48111724853515625\n",
      "cost time:5.4997498989105225 s\n",
      "Epoch 81 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 82 ---------\n",
      "iter   0 | Recons loss=124.302734375 | theta_var_mean=0.0670129805803299\n",
      "iter  10 | Recons loss=84.67716979980469 | theta_var_mean=-0.25209841132164\n",
      "iter  20 | Recons loss=91.88798522949219 | theta_var_mean=-0.4823894500732422\n",
      "cost time:5.40154767036438 s\n",
      "Epoch 82 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 83 ---------\n",
      "iter   0 | Recons loss=124.28950500488281 | theta_var_mean=0.06701507419347763\n",
      "iter  10 | Recons loss=84.68653869628906 | theta_var_mean=-0.2515393793582916\n",
      "iter  20 | Recons loss=91.90054321289062 | theta_var_mean=-0.4811736047267914\n",
      "cost time:5.451420545578003 s\n",
      "Epoch 83 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 84 ---------\n",
      "iter   0 | Recons loss=124.30450439453125 | theta_var_mean=0.06702113151550293\n",
      "iter  10 | Recons loss=84.67631530761719 | theta_var_mean=-0.2524094581604004\n",
      "iter  20 | Recons loss=91.88789367675781 | theta_var_mean=-0.4827561378479004\n",
      "cost time:5.526647090911865 s\n",
      "Epoch 84 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 85 ---------\n",
      "iter   0 | Recons loss=124.2903060913086 | theta_var_mean=0.06701593101024628\n",
      "iter  10 | Recons loss=84.68675994873047 | theta_var_mean=-0.2514983117580414\n",
      "iter  20 | Recons loss=91.90577697753906 | theta_var_mean=-0.48125138878822327\n",
      "cost time:5.418179035186768 s\n",
      "Epoch 85 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 86 ---------\n",
      "iter   0 | Recons loss=124.30192565917969 | theta_var_mean=0.06701870262622833\n",
      "iter  10 | Recons loss=84.67750549316406 | theta_var_mean=-0.2520592212677002\n",
      "iter  20 | Recons loss=91.8841323852539 | theta_var_mean=-0.4824577271938324\n",
      "cost time:5.463099002838135 s\n",
      "Epoch 86 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 87 ---------\n",
      "iter   0 | Recons loss=124.28955078125 | theta_var_mean=0.06700601428747177\n",
      "iter  10 | Recons loss=84.68741607666016 | theta_var_mean=-0.25136566162109375\n",
      "iter  20 | Recons loss=91.90354919433594 | theta_var_mean=-0.48097115755081177\n",
      "cost time:5.5815749168396 s\n",
      "Epoch 87 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 88 ---------\n",
      "iter   0 | Recons loss=124.306396484375 | theta_var_mean=0.06700558960437775\n",
      "iter  10 | Recons loss=84.67611694335938 | theta_var_mean=-0.2525913119316101\n",
      "iter  20 | Recons loss=91.8871841430664 | theta_var_mean=-0.4828607141971588\n",
      "cost time:5.43219256401062 s\n",
      "Epoch 88 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 89 ---------\n",
      "iter   0 | Recons loss=124.29246520996094 | theta_var_mean=0.06702671200037003\n",
      "iter  10 | Recons loss=84.6861572265625 | theta_var_mean=-0.25154581665992737\n",
      "iter  20 | Recons loss=91.90479278564453 | theta_var_mean=-0.4813196063041687\n",
      "cost time:5.461685657501221 s\n",
      "Epoch 89 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 90 ---------\n",
      "iter   0 | Recons loss=124.30519104003906 | theta_var_mean=0.06702566146850586\n",
      "iter  10 | Recons loss=84.67887878417969 | theta_var_mean=-0.2522500455379486\n",
      "iter  20 | Recons loss=91.88520812988281 | theta_var_mean=-0.48258981108665466\n",
      "cost time:5.489232540130615 s\n",
      "Epoch 90 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 91 ---------\n",
      "iter   0 | Recons loss=124.28840637207031 | theta_var_mean=0.06701540946960449\n",
      "iter  10 | Recons loss=84.68507385253906 | theta_var_mean=-0.2513735890388489\n",
      "iter  20 | Recons loss=91.90145111083984 | theta_var_mean=-0.481099933385849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost time:5.398433446884155 s\n",
      "Epoch 91 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 92 ---------\n",
      "iter   0 | Recons loss=124.30445861816406 | theta_var_mean=0.06701664626598358\n",
      "iter  10 | Recons loss=84.6777114868164 | theta_var_mean=-0.2521441578865051\n",
      "iter  20 | Recons loss=91.88783264160156 | theta_var_mean=-0.4825613498687744\n",
      "cost time:5.480885982513428 s\n",
      "Epoch 92 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 93 ---------\n",
      "iter   0 | Recons loss=124.28946685791016 | theta_var_mean=0.0670262798666954\n",
      "iter  10 | Recons loss=84.6865005493164 | theta_var_mean=-0.25145187973976135\n",
      "iter  20 | Recons loss=91.90020751953125 | theta_var_mean=-0.48108258843421936\n",
      "cost time:5.450551509857178 s\n",
      "Epoch 93 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 94 ---------\n",
      "iter   0 | Recons loss=124.3060531616211 | theta_var_mean=0.06701865047216415\n",
      "iter  10 | Recons loss=84.67838287353516 | theta_var_mean=-0.2524740695953369\n",
      "iter  20 | Recons loss=91.88838195800781 | theta_var_mean=-0.48286113142967224\n",
      "cost time:5.41630482673645 s\n",
      "Epoch 94 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 95 ---------\n",
      "iter   0 | Recons loss=124.29071044921875 | theta_var_mean=0.06704612076282501\n",
      "iter  10 | Recons loss=84.68683624267578 | theta_var_mean=-0.2513793408870697\n",
      "iter  20 | Recons loss=91.90219116210938 | theta_var_mean=-0.4811159074306488\n",
      "cost time:5.44100022315979 s\n",
      "Epoch 95 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 96 ---------\n",
      "iter   0 | Recons loss=124.30506896972656 | theta_var_mean=0.06701650470495224\n",
      "iter  10 | Recons loss=84.6772689819336 | theta_var_mean=-0.2523065507411957\n",
      "iter  20 | Recons loss=91.88665771484375 | theta_var_mean=-0.48279303312301636\n",
      "cost time:5.505663633346558 s\n",
      "Epoch 96 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 97 ---------\n",
      "iter   0 | Recons loss=124.2889404296875 | theta_var_mean=0.06702522933483124\n",
      "iter  10 | Recons loss=84.68704986572266 | theta_var_mean=-0.2511523365974426\n",
      "iter  20 | Recons loss=91.90278625488281 | theta_var_mean=-0.4807823598384857\n",
      "cost time:5.379982948303223 s\n",
      "Epoch 97 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 98 ---------\n",
      "iter   0 | Recons loss=124.3089370727539 | theta_var_mean=0.06699967384338379\n",
      "iter  10 | Recons loss=84.67601013183594 | theta_var_mean=-0.2525533139705658\n",
      "iter  20 | Recons loss=91.88764190673828 | theta_var_mean=-0.4829012453556061\n",
      "cost time:5.4895195960998535 s\n",
      "Epoch 98 training finished\n",
      "save theta and disparity at output/\n",
      "--------- Epoch 99 ---------\n",
      "iter   0 | Recons loss=124.28715515136719 | theta_var_mean=0.06703357398509979\n",
      "iter  10 | Recons loss=84.68695068359375 | theta_var_mean=-0.25146499276161194\n",
      "iter  20 | Recons loss=91.9013442993164 | theta_var_mean=-0.481167733669281\n",
      "cost time:5.486089468002319 s\n",
      "Epoch 99 training finished\n",
      "save theta and disparity at output/\n"
     ]
    }
   ],
   "source": [
    "%run std_tps.py --model 'TPS' --cpts_row 4 --cpts_col 4 --output_directory output/ --epoch_num 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alternative training Model : OTPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run o_tps.py --pretrained False --cpts_row 4 --cpts_col 4  --epoch_num 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run o_tps.py --cpts_row 4 --cpts_col 4 --pretrained True --epoch_num 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set  `--pretrain True` to load last trained T and theta of OTPS for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After otps training, you can find a T file at `/<output_directory>/T_trained.npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set `--model OTPS` to load trained T of OTPS model for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run std_tps.py --model 'OTPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
